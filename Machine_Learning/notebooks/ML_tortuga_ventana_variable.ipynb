{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, recall_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leer archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and preprocessing\n",
    "data_train = pd.read_csv('C:/Users/carlo/Desktop/Tesis/Predicciones/Machine_Learning/Archivos_CSV_con_etiquetas/Tortu_Erika_Completo_ordenado_train_Balanceado_QuietaComiendoCaminando.csv')\n",
    "data_test = pd.read_csv('C:/Users/carlo/Desktop/Tesis/Predicciones/Machine_Learning/Archivos_CSV_con_etiquetas/Tortu_Erika_Completo_ordenado_test_Balanceado_QuietaComiendoCaminando.csv')\n",
    "data_train['dateTime_UTC'] = pd.to_datetime(data_train['dateTime_UTC'], errors='coerce')\n",
    "data_test['dateTime_UTC'] = pd.to_datetime(data_test['dateTime_UTC'], errors='coerce')\n",
    "df_train = data_train[data_train['dateTime_UTC'].notna()]\n",
    "df_test = data_test[data_test['dateTime_UTC'].notna()]\n",
    "df_train = df_train.sort_values(by=['dateTime_UTC'], ignore_index=True)\n",
    "df_test = df_test.sort_values(by=['dateTime_UTC'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones creacion ventanas y calculo features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "\n",
    "def compute_features(x_df, y_df, z_df, gx_df, gy_df, gz_df, window_size):\n",
    "    X = pd.DataFrame()\n",
    "    acc_magnitude = np.sqrt(x_df**2 + y_df**2 + z_df**2)\n",
    "    gyro_magnitude = np.sqrt(gx_df**2 + gy_df**2 + gz_df**2)\n",
    "    for name, df in zip(\n",
    "        ['x', 'y', 'z', 'gx', 'gy', 'gz', 'acc_mag', 'gyro_mag'],\n",
    "        [x_df, y_df, z_df, gx_df, gy_df, gz_df, acc_magnitude, gyro_magnitude]\n",
    "    ):\n",
    "        X[f'{name}_mean'] = df.mean(axis=1)\n",
    "        X[f'{name}_std'] = df.std(axis=1)\n",
    "        X[f'{name}_median'] = df.median(axis=1)\n",
    "        X[f'{name}_mad'] = np.median(np.abs(df - np.median(df, axis=1)[:, None]), axis=1)\n",
    "        X[f'{name}_iqr'] = df.apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25), axis=1)\n",
    "        X[f'{name}_peak_count'] = df.apply(lambda x: len(find_peaks(x)[0]), axis=1)\n",
    "        X[f'{name}_energy'] = np.sum(df**2, axis=1) / window_size\n",
    "    X['sma'] = (np.sum(np.abs(x_df), axis=1) + np.sum(np.abs(y_df), axis=1) + np.sum(np.abs(z_df), axis=1)) / window_size\n",
    "    X['sma_gyro'] = (np.sum(np.abs(gx_df), axis=1) + np.sum(np.abs(gy_df), axis=1) + np.sum(np.abs(gz_df), axis=1)) / window_size\n",
    "\n",
    "    # FFT Features\n",
    "    def fft_basic_features(df):\n",
    "        fft_vals = np.abs(np.fft.rfft(df, axis=1))\n",
    "        return {\n",
    "            'fft_mean': fft_vals.mean(axis=1),\n",
    "            'fft_std': fft_vals.std(axis=1),\n",
    "            'fft_max': fft_vals.max(axis=1),\n",
    "            'fft_energy': np.sum(fft_vals**2, axis=1)\n",
    "        }\n",
    "    for name, df in zip(['x', 'y', 'z', 'gx', 'gy', 'gz'], [x_df, y_df, z_df, gx_df, gy_df, gz_df]):\n",
    "        fft_feats = fft_basic_features(df)\n",
    "        for k, v in fft_feats.items():\n",
    "            X[f'{name}_{k}'] = v\n",
    "\n",
    "    # Entropy\n",
    "    def shannon_entropy(signal):\n",
    "        hist, _ = np.histogram(signal, bins=10, density=True)\n",
    "        hist += 1e-12\n",
    "        return -np.sum(hist * np.log2(hist))\n",
    "    for name, df in zip(['x', 'y', 'z', 'gx', 'gy', 'gz'], [x_df, y_df, z_df, gx_df, gy_df, gz_df]):\n",
    "        X[f'{name}_entropy'] = df.apply(shannon_entropy, axis=1)\n",
    "\n",
    "    # Correlation features\n",
    "    X['corr_xy'] = [np.corrcoef(x, y)[0,1] for x, y in zip(x_df.values, y_df.values)]\n",
    "    X['corr_xz'] = [np.corrcoef(x, z)[0,1] for x, z in zip(x_df.values, z_df.values)]\n",
    "    X['corr_yz'] = [np.corrcoef(y, z)[0,1] for y, z in zip(y_df.values, z_df.values)]\n",
    "\n",
    "    # Zero crossing rate\n",
    "    def zero_crossings(signal):\n",
    "        return ((signal[:, :-1] * signal[:, 1:]) < 0).sum(axis=1)\n",
    "    X['x_zero_cross'] = zero_crossings(x_df.values)\n",
    "    X['y_zero_cross'] = zero_crossings(y_df.values)\n",
    "    X['z_zero_cross'] = zero_crossings(z_df.values)\n",
    "\n",
    "    X.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    X.fillna(0, inplace=True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(df, window_size, step_size):\n",
    "    x_list, y_list, z_list, gx_list, gy_list, gz_list, labels = [], [], [], [], [], [], []\n",
    "    for i in range(0, df.shape[0] - window_size, step_size):\n",
    "        xs = df['ax'].values[i: i + window_size]\n",
    "        ys = df['ay'].values[i: i + window_size]\n",
    "        zs = df['az'].values[i: i + window_size]\n",
    "        gx = df['gx'].values[i: i + window_size]\n",
    "        gy = df['gy'].values[i: i + window_size]\n",
    "        gz = df['gz'].values[i: i + window_size]\n",
    "        label = df['Actividades'][i: i + window_size].mode()[0]\n",
    "        x_list.append(xs)\n",
    "        y_list.append(ys)\n",
    "        z_list.append(zs)\n",
    "        gx_list.append(gx)\n",
    "        gy_list.append(gy)\n",
    "        gz_list.append(gz)\n",
    "        labels.append(label)\n",
    "    return x_list, y_list, z_list, gx_list, gy_list, gz_list, labels\n",
    "\n",
    "def remove_correlated_features(X_train, X_test, threshold=0.9):\n",
    "    corr_matrix = X_train.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    X_train_reduced = X_train.drop(columns=to_drop)\n",
    "    X_test_reduced = X_test.drop(columns=to_drop)\n",
    "    return X_train_reduced, X_test_reduced, to_drop\n",
    "\n",
    "def smote(X,y):\n",
    "    smote = SMOTE(random_state=21)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def tune_logistic_regression(X, y):\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['lbfgs', 'liblinear'],\n",
    "        'max_iter': [100, 200, 300],\n",
    "    }\n",
    "    lr = LogisticRegression(random_state=21)\n",
    "    grid_search = GridSearchCV(estimator=lr, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "def tune_random_forest(X, y):\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10, 20]\n",
    "    }\n",
    "    rf = RandomForestClassifier(random_state=21)\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "def tune_svm(X, y):\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'gamma': ['scale', 0.01, 0.1]\n",
    "    }\n",
    "    svm = SVC(kernel='rbf', random_state=21, probability=True)\n",
    "    grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "def tune_xgb(X, y):\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "    xgb_clf = xgb.XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=xgb_clf, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "def tune_voting(X,y, base_models):\n",
    "    voting_clf = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('lr', base_models['lr']),\n",
    "            ('rf', base_models['rf']),\n",
    "            ('svm', base_models['svm']),\n",
    "            ('xgb', base_models['xgb'])\n",
    "        ],\n",
    "        voting='hard',\n",
    "        weights=[3, 10, 3, 8]  # Adjust weights as needed\n",
    "    )\n",
    "    voting_clf.fit(X, y)\n",
    "    return voting_clf\n",
    "\n",
    "def calcular_static_dynamic(df, freq=14.45354719, window_seconds=10):\n",
    "    window_size = int(freq * window_seconds)\n",
    "    df['sax'] = df['ax'].rolling(window=window_size, center=True, min_periods=1).mean()\n",
    "    df['say'] = df['ay'].rolling(window=window_size, center=True, min_periods=1).mean()\n",
    "    df['saz'] = df['az'].rolling(window=window_size, center=True, min_periods=1).mean()\n",
    "    df['sgx'] = df['gx'].rolling(window=window_size, center=True, min_periods=1).mean()\n",
    "    df['sgy'] = df['gy'].rolling(window=window_size, center=True, min_periods=1).mean()\n",
    "    df['sgz'] = df['gz'].rolling(window=window_size, center=True, min_periods=1).mean()\n",
    "    df['ax'] = np.abs(df['ax'] - df['sax'])\n",
    "    df['ay'] = np.abs(df['ay'] - df['say'])\n",
    "    df['az'] = np.abs(df['az'] - df['saz'])\n",
    "    df['gx'] = np.abs(df['gx'] - df['sgx'])\n",
    "    df['gy'] = np.abs(df['gy'] - df['sgy'])\n",
    "    df['gz'] = np.abs(df['gz'] - df['sgz'])\n",
    "    return df\n",
    "\n",
    "def encode_labels(labels, diccionario_codificacion):\n",
    "    return np.array([diccionario_codificacion[str(label)] for label in labels])\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "        y_true, y_pred, labels, title,\n",
    "        num_fontsize=14, label_fontsize=12, title_fontsize=14,\n",
    "        cbar_fontsize=10):\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='Blues',\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        annot_kws={\"size\": num_fontsize}\n",
    "    )\n",
    "\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=cbar_fontsize)\n",
    "\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "    plt.xlabel('Predicciones', fontsize=label_fontsize)\n",
    "    plt.ylabel('Valores reales', fontsize=label_fontsize)\n",
    "    plt.xticks(fontsize=label_fontsize)\n",
    "    plt.yticks(fontsize=label_fontsize)\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_importance(model, feature_names, top_n=20):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1][:top_n]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Feature Importances\")\n",
    "    plt.bar(range(top_n), importances[indices])\n",
    "    plt.xticks(range(top_n), [feature_names[i] for i in indices], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varío tamaño ventana, creo modelos, predigo, calculo accuracy, precisión, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed: 22.2min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed: 30.5min\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed: 36.9min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 45.0min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed: 50.1min\n",
      "[Parallel(n_jobs=-1)]: Done  77 out of  98 | elapsed: 53.2min remaining: 14.5min\n",
      "[Parallel(n_jobs=-1)]: Done  87 out of  98 | elapsed: 55.7min remaining:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done  98 out of  98 | elapsed: 64.5min finished\n"
     ]
    }
   ],
   "source": [
    "def evaluate_window(i):\n",
    "    window_size = i + 2  # Evitar ventana de tamaño 0\n",
    "    step_size = window_size // 2\n",
    "    x_list_train, y_list_train, z_list_train, gx_list_train, gy_list_train, gz_list_train, train_labels = create_windows(df_train, window_size, step_size)\n",
    "    x_df_train = pd.DataFrame(x_list_train)\n",
    "    y_df_train = pd.DataFrame(y_list_train)\n",
    "    z_df_train = pd.DataFrame(z_list_train)\n",
    "    gx_df_train = pd.DataFrame(gx_list_train)\n",
    "    gy_df_train = pd.DataFrame(gy_list_train)\n",
    "    gz_df_train = pd.DataFrame(gz_list_train)\n",
    "    X_train = compute_features(x_df_train, y_df_train, z_df_train, gx_df_train, gy_df_train, gz_df_train, window_size)\n",
    "\n",
    "    x_list_test, y_list_test, z_list_test, gx_list_test, gy_list_test, gz_list_test, test_labels = create_windows(df_test, window_size, step_size)\n",
    "    x_df_test = pd.DataFrame(x_list_test)\n",
    "    y_df_test = pd.DataFrame(y_list_test)\n",
    "    z_df_test = pd.DataFrame(z_list_test)\n",
    "    gx_df_test = pd.DataFrame(gx_list_test)\n",
    "    gy_df_test = pd.DataFrame(gy_list_test)\n",
    "    gz_df_test = pd.DataFrame(gz_list_test)\n",
    "    X_test = compute_features(x_df_test, y_df_test, z_df_test, gx_df_test, gy_df_test, gz_df_test, window_size)\n",
    "\n",
    "    # Label encoding\n",
    "    diccionario_codificacion = {'Quieta': 0, 'Caminando': 1, 'Comiendo': 2}\n",
    "    #diccionario_codificacion = {'Quieto': 0, 'Movimiento_1': 1, 'Movimiento_2': 2, 'Movimiento_3': 3, 'Movimiento_4': 4}\n",
    "    train_labels = encode_labels(train_labels, diccionario_codificacion)\n",
    "    test_labels = encode_labels(test_labels, diccionario_codificacion)\n",
    "\n",
    "    # Feature selection (remove correlated features)\n",
    "    X_train_reduced, X_test_reduced, to_drop = remove_correlated_features(X_train, X_test, threshold=0.9)\n",
    "    # print(f\"Features eliminadas por correlación > 0.9:\\n{to_drop}\")\n",
    "\n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_reduced)\n",
    "    X_test_scaled = scaler.transform(X_test_reduced)\n",
    "\n",
    "    # #SMOTE (balancing the dataset)\n",
    "    # X_train_scaled, train_labels = smote(X_train_scaled, train_labels)\n",
    "\n",
    "    # Model training and hyperparameter tuning\n",
    "    lr_best, lr_params = tune_logistic_regression(X_train_scaled, train_labels)\n",
    "    rf_best, rf_params = tune_random_forest(X_train_scaled, train_labels)\n",
    "    svm_best, svm_params = tune_svm(X_train_scaled, train_labels)\n",
    "    xgb_best, xgb_params = tune_xgb(X_train_scaled, train_labels)\n",
    "    voting_clf= tune_voting(X_train_scaled, train_labels, base_models={'lr': lr_best, 'rf': rf_best, 'svm': svm_best, 'xgb': xgb_best})\n",
    "\n",
    "    print(\"Best Logistic Regression params:\", lr_params)\n",
    "    print(\"Best Random Forest params:\", rf_params)\n",
    "    print(\"Best SVM params:\", svm_params)\n",
    "    print(\"Best XGB params:\", xgb_params)\n",
    "\n",
    "    # Evaluation\n",
    "    pred_lr = lr_best.predict(X_test_scaled)\n",
    "    pred_rf = rf_best.predict(X_test_scaled)\n",
    "    pred_svm = svm_best.predict(X_test_scaled)\n",
    "    pred_xgb = xgb_best.predict(X_test_scaled)\n",
    "    pred_voting = voting_clf.predict(X_test_scaled)\n",
    "\n",
    "    acc_lr = accuracy_score(test_labels, pred_lr)\n",
    "    acc_rf = accuracy_score(test_labels, pred_rf)\n",
    "    acc_svm = accuracy_score(test_labels, pred_svm)\n",
    "    acc_xgb = accuracy_score(test_labels, pred_xgb)\n",
    "    acc_voting = accuracy_score(test_labels, pred_voting)\n",
    "\n",
    "    prec_lr, rec_lr, fsc_lr, _ = precision_recall_fscore_support(test_labels, pred_lr, average=None, zero_division=0)\n",
    "    prec_rf, rec_rf, fsc_rf, _ = precision_recall_fscore_support(test_labels, pred_rf, average=None, zero_division=0)\n",
    "    prec_svm, rec_svm, fsc_svm, _ = precision_recall_fscore_support(test_labels, pred_svm, average=None, zero_division=0)\n",
    "    prec_xgb, rec_xgb, fsc_xgb, _ = precision_recall_fscore_support(test_labels, pred_xgb, average=None, zero_division=0)\n",
    "    prec_voting, rec_voting, fsc_voting, _ = precision_recall_fscore_support(test_labels, pred_voting, average=None, zero_division=0)\n",
    "\n",
    "    print(f\"Window size: {window_size}, RF Accuracy: {acc_rf:.4f}, Params: {rf_params}\")\n",
    "    return {\n",
    "        'window': window_size,\n",
    "        # LR\n",
    "        'acc_lr': acc_lr, 'prec_lr': prec_lr, 'rec_lr': rec_lr, 'fsc_lr': fsc_lr,\n",
    "        # RF\n",
    "        'acc_rf': acc_rf, 'prec_rf': prec_rf, 'rec_rf': rec_rf, 'fsc_rf': fsc_rf,\n",
    "        # KNN\n",
    "        # 'acc_knn': acc_knn, 'prec_knn': prec_knn, 'rec_knn': rec_knn, 'fsc_knn': fsc_knn,\n",
    "        # SVM\n",
    "        'acc_svm': acc_svm, 'prec_svm': prec_svm, 'rec_svm': rec_svm, 'fsc_svm': fsc_svm,\n",
    "        # XGB\n",
    "        'acc_xgb': acc_xgb, 'prec_xgb': prec_xgb, 'rec_xgb': rec_xgb, 'fsc_xgb': fsc_xgb,\n",
    "        # Voting\n",
    "        'acc_voting': acc_voting, 'prec_voting': prec_voting, 'rec_voting': rec_voting, 'fsc_voting': fsc_voting\n",
    "    }\n",
    "\n",
    "# Paralelización\n",
    "resultados = Parallel(n_jobs=-1, verbose=10)(delayed(evaluate_window)(i) for i in range(98))\n",
    "\n",
    "# # Extraer resultados\n",
    "accuracyX_lr = [r['acc_lr'] for r in resultados]\n",
    "accuracyX_rf = [r['acc_rf'] for r in resultados]\n",
    "# accuracyX_knn = [r['acc_knn'] for r in resultados]\n",
    "accuracyX_svm = [r['acc_svm'] for r in resultados]\n",
    "\n",
    "# Logistic Regression\n",
    "precisionX_lr = [r['prec_lr'] for r in resultados]\n",
    "recallX_lr = [r['rec_lr'] for r in resultados]\n",
    "fscoreX_lr = [r['fsc_lr'] for r in resultados]\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "precisionX_rf = [r['prec_rf'] for r in resultados]\n",
    "recallX_rf = [r['rec_rf'] for r in resultados]\n",
    "fscoreX_rf = [r['fsc_rf'] for r in resultados]\n",
    "\n",
    "# Support Vector Machine\n",
    "precisionX_svm = [r['prec_svm'] for r in resultados]\n",
    "recallX_svm = [r['rec_svm'] for r in resultados]\n",
    "fscoreX_svm = [r['fsc_svm'] for r in resultados]\n",
    "\n",
    "# XGBoost\n",
    "precisionX_xgb = [r['prec_xgb'] for r in resultados]\n",
    "recallX_xgb = [r['rec_xgb'] for r in resultados]\n",
    "fscoreX_xgb = [r['fsc_xgb'] for r in resultados]\n",
    "\n",
    "# voting\n",
    "precisionX_voting = [r['prec_voting'] for r in resultados]\n",
    "recallX_voting = [r['rec_voting'] for r in resultados]\n",
    "fscoreX_voting = [r['fsc_voting'] for r in resultados]\n",
    "\n",
    "windows = [r['window'] for r in resultados]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Variables de precisión para cada actividad random forest\n",
    "precision_caminando_rf = [array[0] for array in precisionX_rf]\n",
    "precision_quieta_rf = [array[1] for array in precisionX_rf]\n",
    "precision_come_rf = [array[2] for array in precisionX_rf]\n",
    "\n",
    "# Variables de precisión para cada actividad regresión logística\n",
    "precision_caminando_lr = [array[0] for array in precisionX_lr]\n",
    "precision_quieta_lr = [array[1] for array in precisionX_lr]\n",
    "precision_come_lr = [array[2] for array in precisionX_lr]\n",
    "\n",
    "# Variables de precisión para SVM \n",
    "precision_caminando_svm = [array[0] for array in precisionX_svm]\n",
    "precision_quieta_svm = [array[1] for array in precisionX_svm]\n",
    "precision_come_svm = [array[2] for array in precisionX_svm]\n",
    "\n",
    "#Variables de precisión para XGBoost\n",
    "precision_caminando_xgb = [array[0] for array in precisionX_xgb]\n",
    "precision_quieta_xgb = [array[1] for array in precisionX_xgb]\n",
    "precision_come_xgb = [array[2] for array in precisionX_xgb]\n",
    "\n",
    "# Variables de precisión para Voting\n",
    "precision_caminando_voting = [array[0] for array in precisionX_voting]\n",
    "precision_quieta_voting = [array[1] for array in precisionX_voting]\n",
    "precision_come_voting = [array[2] for array in precisionX_voting]\n",
    "\n",
    "# Crear los gráficos\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(5, 1, sharex=True, sharey=True, figsize=(10, 12))\n",
    "\n",
    "# Gráfico para Random Forest\n",
    "ax1.plot(windows, precision_caminando_rf, label='Caminando', color='red')\n",
    "ax1.plot(windows, precision_quieta_rf, label='Quieta', color='blue')\n",
    "ax1.plot(windows, precision_come_rf, label='Comiendo', color='gray')\n",
    "ax1.set_ylabel('Precisión', fontsize=22)\n",
    "ax1.set_title('Random Forest', fontsize=22)\n",
    "\n",
    "# Gráfico para Regresión Logística\n",
    "ax2.plot(windows, precision_caminando_lr, label='Caminando', color='red')\n",
    "ax2.plot(windows, precision_quieta_lr, label='Quieta', color='blue')\n",
    "ax2.plot(windows, precision_come_lr, label='Comiendo', color='gray')\n",
    "ax2.set_ylabel('Precisión', fontsize=22)\n",
    "ax2.set_title('Regresión Logística', fontsize=22)\n",
    "\n",
    "\n",
    "# Gráfico para SVM\n",
    "ax3.plot(windows, precision_caminando_svm, label='Caminando', color='red')\n",
    "ax3.plot(windows, precision_quieta_svm, label='Quieta', color='blue')\n",
    "ax3.plot(windows, precision_come_svm, label='Comiendo', color='gray')\n",
    "ax3.set_ylabel('Precisión', fontsize=22)\n",
    "ax3.set_title('SVM', fontsize=22)\n",
    "\n",
    "#Grafico para XGBoost\n",
    "ax4.plot(windows, precision_caminando_xgb, label='Caminando', color='red')\n",
    "ax4.plot(windows, precision_quieta_xgb, label='Quieta', color='blue')\n",
    "ax4.plot(windows, precision_come_xgb, label='Comiendo', color='gray')\n",
    "ax4.set_ylabel('Precisión', fontsize=22)\n",
    "ax4.set_title('XGBoost', fontsize=22)\n",
    "\n",
    "#Grafico para voting\n",
    "ax5.plot(windows, precision_caminando_voting, label='Caminando', color='red')\n",
    "ax5.plot(windows, precision_quieta_voting, label='Quieta', color='blue')\n",
    "ax5.plot(windows, precision_come_voting, label='Comiendo', color='gray')\n",
    "ax5.set_xlabel('Tamaño de ventanas [N° de mediciones]', fontsize=22)\n",
    "ax5.set_ylabel('Precisión', fontsize=22)\n",
    "ax5.set_title('Voting', fontsize=22)\n",
    "\n",
    "# Personalizar los ticks de los ejes\n",
    "for ax in [ax1, ax2, ax3, ax4, ax5]:\n",
    "    ax.tick_params(axis='x', labelsize=18)\n",
    "    ax.tick_params(axis='y', labelsize=18)\n",
    "\n",
    "# Añadir leyenda\n",
    "ax1.legend(loc=(0.6, 0), fontsize=20)\n",
    "# ax2.legend(loc=(0.6, 0), fontsize=20)\n",
    "# ax3.legend(loc=(0.6, 0), fontsize=20)\n",
    "# ax4.legend(loc=(0.6, 0), fontsize=20)\n",
    "\n",
    "# Mostrar gráfico\n",
    "plt.ylim(0, 1)  # Ajustar límites del eje y\n",
    "plt.tight_layout()  # Asegura que las etiquetas no se superpongan\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Variables de recall para cada actividad random forest\n",
    "recall_caminando_rf = [array[0] for array in recallX_rf]\n",
    "recall_quieta_rf = [array[1] for array in recallX_rf]\n",
    "recall_come_rf = [array[2] for array in recallX_rf]\n",
    "\n",
    "# Variables de recall para cada actividad regresión logística\n",
    "recall_caminando_lr = [array[0] for array in recallX_lr]\n",
    "recall_quieta_lr = [array[1] for array in recallX_lr]\n",
    "recall_come_lr = [array[2] for array in recallX_lr]\n",
    "\n",
    "# Variables de recall para SVM\n",
    "recall_caminando_svm = [array[0] for array in recallX_svm]\n",
    "recall_quieta_svm = [array[1] for array in recallX_svm]\n",
    "recall_come_svm = [array[2] for array in recallX_svm]\n",
    "\n",
    "#Variables de recall para XGBoost\n",
    "recall_caminando_xgb = [array[0] for array in recallX_xgb]\n",
    "recall_quieta_xgb = [array[1] for array in recallX_xgb]\n",
    "recall_come_xgb = [array[2] for array in recallX_xgb]\n",
    "\n",
    "#Variables de recall para Voting\n",
    "recall_caminando_voting = [array[0] for array in recallX_voting]\n",
    "recall_quieta_voting = [array[1] for array in recallX_voting]\n",
    "recall_come_voting = [array[2] for array in recallX_voting]\n",
    "\n",
    "# Crear los gráficos\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(5, 1, sharex=True, sharey=True, figsize=(10, 12))\n",
    "\n",
    "# Gráfico para Random Forest\n",
    "ax1.plot(windows, recall_caminando_rf, label='Caminando', color='red')\n",
    "ax1.plot(windows, recall_quieta_rf, label='Quieta', color='blue')\n",
    "ax1.plot(windows, recall_come_rf, label='Comiendo', color='gray')\n",
    "ax1.set_ylabel('Recall', fontsize=22)\n",
    "ax1.set_title('Random Forest', fontsize=22)\n",
    "\n",
    "#Gráfico para Regresión Logística\n",
    "ax2.plot(windows, recall_caminando_lr, label='Caminando', color='red')\n",
    "ax2.plot(windows, recall_quieta_lr, label='Quieta', color='blue')\n",
    "ax2.plot(windows, recall_come_lr, label='Comiendo', color='gray')\n",
    "ax2.set_ylabel('Recall', fontsize=22)\n",
    "ax2.set_title('Regresión Logística', fontsize=22)\n",
    "\n",
    "\n",
    "#Gráfico para SVM\n",
    "ax3.plot(windows, recall_caminando_svm, label='Caminando', color='red')\n",
    "ax3.plot(windows, recall_quieta_svm, label='Quieta', color='blue')\n",
    "ax3.plot(windows, recall_come_svm, label='Comiendo', color='gray')\n",
    "ax3.set_ylabel('Recall', fontsize=22)\n",
    "ax3.set_title('SVM', fontsize=22)\n",
    "\n",
    "#Gráfico para XGBoost\n",
    "ax4.plot(windows, recall_caminando_xgb, label='Caminando', color='red')\n",
    "ax4.plot(windows, recall_quieta_xgb, label='Quieta', color='blue')\n",
    "ax4.plot(windows, recall_come_xgb, label='Comiendo', color='gray')\n",
    "ax4.set_ylabel('Recall', fontsize=22)\n",
    "ax4.set_title('XGBoost', fontsize=22)\n",
    "\n",
    "#Gráfico para voting\n",
    "ax5.plot(windows, recall_caminando_voting, label='Caminando', color='red')\n",
    "ax5.plot(windows, recall_quieta_voting, label='Quieta', color='blue')\n",
    "ax5.plot(windows, recall_come_voting, label='Comiendo', color='gray')\n",
    "ax5.set_xlabel('Tamaño de ventanas [N° de mediciones]', fontsize=22)\n",
    "ax5.set_ylabel('Recall', fontsize=22)\n",
    "ax5.set_title('Voting', fontsize=22)\n",
    "\n",
    "# Personalizar los ticks de los ejes\n",
    "for ax in [ax1,ax2, ax3, ax4, ax5]:\n",
    "    ax.tick_params(axis='x', labelsize=18)\n",
    "    ax.tick_params(axis='y', labelsize=18)\n",
    "\n",
    "# Añadir leyenda\n",
    "ax1.legend(loc=(0.6, 0), fontsize=20)\n",
    "# ax2.legend(loc=(0.6, 0), fontsize=20)\n",
    "# # ax3.legend(loc=(0.6, 0), fontsize=20)\n",
    "# ax4.legend(loc=(0.6, 0), fontsize=20)\n",
    "\n",
    "# Mostrar gráfico\n",
    "plt.ylim(0, 1)  # Ajustar límites del eje y\n",
    "plt.tight_layout()  # Asegura que las etiquetas no se superpongan\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Variables de f1-score para cada actividad random forest\n",
    "fscore_caminando_rf = [array[0] for array in fscoreX_rf]\n",
    "fscore_quieta_rf = [array[1] for array in fscoreX_rf]\n",
    "fscore_come_rf = [array[2] for array in fscoreX_rf]\n",
    "\n",
    "# Variables de f1-score para cada actividad regresión logística\n",
    "fscore_caminando_lr = [array[0] for array in fscoreX_lr]\n",
    "fscore_quieta_lr = [array[1] for array in fscoreX_lr]\n",
    "fscore_come_lr = [array[2] for array in fscoreX_lr]\n",
    "\n",
    "# Variables de f1-score para SVM \n",
    "fscore_caminando_svm = [array[0] for array in fscoreX_svm]\n",
    "fscore_quieta_svm = [array[1] for array in fscoreX_svm]\n",
    "fscore_come_svm = [array[2] for array in fscoreX_svm]\n",
    "\n",
    "# Variables de f1-score para XGBoost\n",
    "fscore_caminando_xgb = [array[0] for array in fscoreX_xgb]\n",
    "fscore_quieta_xgb = [array[1] for array in fscoreX_xgb]\n",
    "fscore_come_xgb = [array[2] for array in fscoreX_xgb]\n",
    "\n",
    "# Variables de f1-score para Voting\n",
    "fscore_caminando_voting = [array[0] for array in fscoreX_voting]\n",
    "fscore_quieta_voting = [array[1] for array in fscoreX_voting]\n",
    "fscore_come_voting = [array[2] for array in fscoreX_voting]\n",
    "\n",
    "# Crear los gráficos\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(5, 1, sharex=True, sharey=True, figsize=(10, 12))\n",
    "\n",
    "# Gráfico para Random Forest\n",
    "ax1.plot(windows, fscore_caminando_rf, label='Caminando', color='red')\n",
    "ax1.plot(windows, fscore_quieta_rf, label='Quieta', color='blue')\n",
    "ax1.plot(windows, fscore_come_rf, label='Comiendo', color='gray')\n",
    "ax1.set_ylabel('f$_1$-score', fontsize=22)\n",
    "ax1.set_title('Random Forest', fontsize=22)\n",
    "\n",
    "# Gráfico para Regresión Logística\n",
    "ax2.plot(windows, fscore_caminando_lr, label='Caminando', color='red')\n",
    "ax2.plot(windows, fscore_quieta_lr, label='Quieta', color='blue')\n",
    "ax2.plot(windows, fscore_come_lr, label='Comiendo', color='gray')\n",
    "ax2.set_ylabel('f$_1$-score', fontsize=22)\n",
    "ax2.set_title('Regresión Logística', fontsize=22)\n",
    "\n",
    "\n",
    "# Gráfico para SVM\n",
    "ax3.plot(windows, fscore_caminando_svm, label='Caminando', color='red')\n",
    "ax3.plot(windows, fscore_quieta_svm, label='Quieta', color='blue')\n",
    "ax3.plot(windows, fscore_come_svm, label='Comiendo', color='gray')\n",
    "ax3.set_ylabel('f$_1$-score', fontsize=22)\n",
    "ax3.set_title('SVM', fontsize=22)\n",
    "\n",
    "# Gráfico para XGBoost\n",
    "ax4.plot(windows, fscore_caminando_xgb, label='Caminando', color='red')\n",
    "ax4.plot(windows, fscore_quieta_xgb, label='Quieta', color='blue')\n",
    "ax4.plot(windows, fscore_come_xgb, label='Comiendo', color='gray')\n",
    "ax4.set_ylabel('f$_1$-score', fontsize=22)\n",
    "ax4.set_title('XGBoost', fontsize=22)\n",
    "\n",
    "# Gráfico para Voting\n",
    "ax5.plot(windows, fscore_caminando_voting, label='Caminando', color='red')\n",
    "ax5.plot(windows, fscore_quieta_voting, label='Quieta', color='blue')\n",
    "ax5.plot(windows, fscore_come_voting, label='Comiendo', color='gray')\n",
    "ax5.set_xlabel('Tamaño de ventanas [N° de mediciones]', fontsize=22)\n",
    "ax5.set_ylabel('f$_1$-score', fontsize=22)\n",
    "ax5.set_title('Voting', fontsize=22)\n",
    "\n",
    "# Personalizar los ticks de los ejes\n",
    "for ax in [ax1, ax2, ax3, ax4, ax5]:\n",
    "    ax.tick_params(axis='x', labelsize=18)\n",
    "    ax.tick_params(axis='y', labelsize=18)\n",
    "\n",
    "\n",
    "# Añadir leyenda\n",
    "ax1.legend(loc=(0.6, 0), fontsize=20)\n",
    "# ax2.legend(loc=(0.6, 0), fontsize=20)\n",
    "# # ax3.legend(loc=(0.6, 0), fontsize=20)\n",
    "# ax4.legend(loc=(0.6, 0), fontsize=20)\n",
    "\n",
    "# Mostrar gráfico\n",
    "plt.ylim(0, 1)  # Ajustar límites del eje y\n",
    "plt.tight_layout()  # Asegura que las etiquetas no se superpongan\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy vs tamaño ventanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Variables de accuracy para cada modelo\n",
    "accuracyX_lr = [r['acc_lr'] for r in resultados]\n",
    "accuracyX_rf = [r['acc_rf'] for r in resultados]\n",
    "accuracyX_svm = [r['acc_svm'] for r in resultados]  # Asegúrate de que estas variables están definidas\n",
    "accuracyX_xgb = [r['acc_xgb'] for r in resultados]\n",
    "accuracyX_voting = [r['acc_voting'] for r in resultados]\n",
    "\n",
    "# Crear el gráfico para Accuracy de todos los modelos\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 6))  # Un solo gráfico (compartido)\n",
    "\n",
    "# Gráficos de Accuracy para los 4 modelos\n",
    "axs.plot(windows, accuracyX_lr, label='Regresión logística', color='blue')\n",
    "axs.plot(windows, accuracyX_rf, label='Random Forest', color='green')\n",
    "axs.plot(windows, accuracyX_svm, label='SVM', color='orange')\n",
    "axs.plot(windows, accuracyX_xgb, label='XGBoost', color='purple')\n",
    "axs.plot(windows, accuracyX_voting, label='Voting', color='brown')\n",
    "\n",
    "# Establecer título y etiquetas\n",
    "axs.set_title('Accuracy de los modelos vs tamaño de ventana', fontsize=20)\n",
    "axs.set_xlabel('Tamaño de ventanas [N° de mediciones]', fontsize=20)\n",
    "axs.set_ylabel('Accuracy', fontsize=20)\n",
    "\n",
    "# Establecer tamaño de fuente de los ticks\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Añadir leyenda\n",
    "axs.legend(fontsize=14)\n",
    "plt.grid(True)\n",
    "# Mostrar gráfico\n",
    "plt.ylim(0, 1.1)  \n",
    "plt.tight_layout()  \n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
